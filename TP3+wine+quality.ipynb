{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3: Apprentissage Statistique - Wine Quality Database\n",
    "Auteurs: Thomas Levy, Selim Dekali\n",
    "\n",
    "## Introduction\n",
    "Nous avons choisi d'analyser des données sur la qualité du vin du type \"Vinho Verde\" venant du Portugal (https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
    "La qualité du vin est donnée sur une échelle de 0 à 10 ainsi que 11 variables relatives aux vins.\n",
    "\n",
    "Nous avons choisi d'aborder ce problème en essayant de prédire la qualité exacte du vin en fonction des 11 autres variables. \n",
    "Donc, sous forme d'un problème de classification supervisée multi-classes.\n",
    "\n",
    "**NOTE**: Nous aurions également pu transformer la qualité du vin en un nombre de classes plus réduites (du type: mauvais, moyen, bon). \n",
    "Ce qui aurait été un problème probablement plus simple à résoudre mais également moins interessant!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "library(quantmod)\n",
    "\n",
    "#install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "\n",
    "#install.packages(\"outliers\")\n",
    "library(outliers)\n",
    "\n",
    "#install.packages(\"adabag\")\n",
    "library(adabag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import et mise en forme des données\n",
    "Nous récupérons les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "red <- read.csv(url(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"), sep = \";\")\n",
    "white <- read.csv(url(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"), sep = \";\")\n",
    "\n",
    "red$Color <- \"red\"\n",
    "white$Color <- \"white\"\n",
    "Wines <- rbind(red, white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous transformons les variables Color et qualité en facteurs afin de pouvoir traiter le problème sous forme de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wines$quality <- as.factor(Wines$quality)\n",
    "Wines$Color <- as.factor(Wines$Color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse simple des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n",
       " Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n",
       " 1st Qu.: 6.400   1st Qu.:0.2300   1st Qu.:0.2500   1st Qu.: 1.800  \n",
       " Median : 7.000   Median :0.2900   Median :0.3100   Median : 3.000  \n",
       " Mean   : 7.215   Mean   :0.3397   Mean   :0.3186   Mean   : 5.443  \n",
       " 3rd Qu.: 7.700   3rd Qu.:0.4000   3rd Qu.:0.3900   3rd Qu.: 8.100  \n",
       " Max.   :15.900   Max.   :1.5800   Max.   :1.6600   Max.   :65.800  \n",
       "                                                                    \n",
       "   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n",
       " Min.   :0.00900   Min.   :  1.00      Min.   :  6.0        Min.   :0.9871  \n",
       " 1st Qu.:0.03800   1st Qu.: 17.00      1st Qu.: 77.0        1st Qu.:0.9923  \n",
       " Median :0.04700   Median : 29.00      Median :118.0        Median :0.9949  \n",
       " Mean   :0.05603   Mean   : 30.53      Mean   :115.7        Mean   :0.9947  \n",
       " 3rd Qu.:0.06500   3rd Qu.: 41.00      3rd Qu.:156.0        3rd Qu.:0.9970  \n",
       " Max.   :0.61100   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n",
       "                                                                            \n",
       "       pH          sulphates         alcohol      quality    Color     \n",
       " Min.   :2.720   Min.   :0.2200   Min.   : 8.00   3:  30   red  :1599  \n",
       " 1st Qu.:3.110   1st Qu.:0.4300   1st Qu.: 9.50   4: 216   white:4898  \n",
       " Median :3.210   Median :0.5100   Median :10.30   5:2138               \n",
       " Mean   :3.219   Mean   :0.5313   Mean   :10.49   6:2836               \n",
       " 3rd Qu.:3.320   3rd Qu.:0.6000   3rd Qu.:11.30   7:1079               \n",
       " Max.   :4.010   Max.   :2.0000   Max.   :14.90   8: 193               \n",
       "                                                  9:   5               "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "__ignored__": ""
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>30</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>216</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>2138</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>2836</dd>\n",
       "\t<dt>7</dt>\n",
       "\t\t<dd>1079</dd>\n",
       "\t<dt>8</dt>\n",
       "\t\t<dd>193</dd>\n",
       "\t<dt>9</dt>\n",
       "\t\t<dd>5</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[3] 30\n",
       "\\item[4] 216\n",
       "\\item[5] 2138\n",
       "\\item[6] 2836\n",
       "\\item[7] 1079\n",
       "\\item[8] 193\n",
       "\\item[9] 5\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "3\n",
       ":   304\n",
       ":   2165\n",
       ":   21386\n",
       ":   28367\n",
       ":   10798\n",
       ":   1939\n",
       ":   5\n",
       "\n"
      ],
      "text/plain": [
       "   3    4    5    6    7    8    9 \n",
       "  30  216 2138 2836 1079  193    5 "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "__ignored__": ""
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Wines$quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg viewBox='0 0 720.00 360.00'><defs>  <style type='text/css'><![CDATA[    line, polyline, polygon, path, rect, circle {      fill: none;      stroke: #000000;      stroke-linecap: round;      stroke-linejoin: round;      stroke-miterlimit: 10.00;    }  ]]></style></defs><rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/><rect x='82.40' y='281.92' width='71.22' height='2.38' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='167.86' y='267.15' width='71.22' height='17.16' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='253.33' y='114.48' width='71.22' height='169.82' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='338.79' y='59.04' width='71.22' height='225.27' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='424.25' y='198.60' width='71.22' height='85.71' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='509.72' y='268.98' width='71.22' height='15.33' style='stroke-width: 0.75; fill: #BEBEBE;' /><rect x='595.18' y='283.91' width='71.22' height='0.40' style='stroke-width: 0.75; fill: #BEBEBE;' /><text x='114.67' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>3</text><text x='200.14' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>4</text><text x='285.60' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>5</text><text x='371.06' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>6</text><text x='456.53' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>7</text><text x='541.99' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>8</text><text x='627.45' y='312.48' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>9</text><line x1='59.04' y1='284.31' x2='59.04' y2='85.73' style='stroke-width: 0.75;' /><line x1='59.04' y1='284.31' x2='51.84' y2='284.31' style='stroke-width: 0.75;' /><line x1='59.04' y1='244.59' x2='51.84' y2='244.59' style='stroke-width: 0.75;' /><line x1='59.04' y1='204.88' x2='51.84' y2='204.88' style='stroke-width: 0.75;' /><line x1='59.04' y1='165.16' x2='51.84' y2='165.16' style='stroke-width: 0.75;' /><line x1='59.04' y1='125.44' x2='51.84' y2='125.44' style='stroke-width: 0.75;' /><line x1='59.04' y1='85.73' x2='51.84' y2='85.73' style='stroke-width: 0.75;' /><text transform='translate(41.76,287.64) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='6.67px' lengthAdjust='spacingAndGlyphs'>0</text><text transform='translate(41.76,254.60) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='20.02px' lengthAdjust='spacingAndGlyphs'>500</text><text transform='translate(41.76,218.22) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='26.70px' lengthAdjust='spacingAndGlyphs'>1000</text><text transform='translate(41.76,178.51) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='26.70px' lengthAdjust='spacingAndGlyphs'>1500</text><text transform='translate(41.76,138.79) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='26.70px' lengthAdjust='spacingAndGlyphs'>2000</text><text transform='translate(41.76,99.08) rotate(-90)' style='font-size: 12.00px; font-family: Arial;' textLength='26.70px' lengthAdjust='spacingAndGlyphs'>2500</text></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "barplot(table(Wines$quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que les données de qualité sont très déséquilibrés. \n",
    "Il y a majoritairement du vin de qualité moyenne (qualité 6 et 7) mais quasiment pas de vin dont la qualité est:\n",
    "* soit excellente (9 ou 10) \n",
    "* ou trés mauvaise (3 ou moins)\n",
    "\n",
    "Dans un premier temps, on conserve ces données déséquilibrées mais on verra plus tard si on ne peut pas équilibrer ces données.\n",
    "\n",
    "## Préparation pour l'apprentissage statistiques\n",
    "On sépare les données en train & test (75% utilisé pour l'apprentissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_ind <- sample(nrow(Wines), 0.75 * nrow(Wines))\n",
    "train <- Wines[wine_ind, ]\n",
    "test <- Wines[-wine_ind, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "On va essayer un abre de décision en faisant de la cross-validation de type V-fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use a decision tree\n",
    "library(rpart)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_cross <- tune.rpart(quality~., data = train, minsplit = c(2, 3, 5), minbucket= c(1, 3, 5), cp= seq(0.01, 0.1, 0.02),\n",
    "                       tunecontrol = tune.control(sampling = 'cross', cross = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cross$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cross$best.performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La performance du modele avec les hyper-parametres optimaux ne semble pas trés bonne.\n",
    "\n",
    "On va tester le modele sur nos données de test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt.quality = rpart(quality ~., data = train, method= \"class\", minsplit=2, minbucket=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt.predictions = predict(rt.quality, data = test, type= \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.predictions = predict(rt.quality, test, type= \"class\")\n",
    "currentError = sum(rt.predictions!=test[,'quality'])/nrow(test)\n",
    "print(currentError)\n",
    "summary(rt.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf <- table(rt.predictions, test[,'quality'])\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Les résultats de prédictions sont médiocres et le modèle ne prédit que peu de classes (2 ou 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "On va essayer le modele SVM. \n",
    "On va faire de la cross-validation pour selectionner les paramétres optimaux parmi:\n",
    "- la fonction kernel \n",
    "- gamma\n",
    "- cost (le cout de la violation de contrainte)\n",
    "    \n",
    "**NOTE**: Il est à noter que SVM intégre la normalisation des variables (donc inutile de le faire en entrée)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_cross <- tune(svm, quality ~., data = train,\n",
    "                  ranges = list(kernel =c('radial', 'sigmoid', 'linear'),\n",
    "                                gamma = c(0.5, 1, 2, 4),\n",
    "                                cost = c(0.1, 1, 10, 100, 1000)),\n",
    "                  tunecontrol = tune.control(sampling = 'cross', cross = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_cross$best.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_cross$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.model <- svm(quality ~ ., data = train, kernel='radial', cost = 10, gamma = 1)\n",
    "svm.pred <- predict(svm.model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(svm.pred, test$quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentError = sum(svm.pred!=test[,'quality'])/nrow(test)\n",
    "print(currentError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons trouvé un modèle optimal avec kernel gaussien (\"radial\"), gamma de 1 et cost 10.\n",
    "\n",
    "L'erreur de prédiction ést plus faible que précedemment. \n",
    "De plus, la matrice de confusion montre que SVM prédit mieux les classes avec un petit nombre d'observation que ce que nous avons testé au préalable.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KNN\n",
    "Nous allons également essayé le modèle kNN.\n",
    "Cette fois, il est utile de normaliser les variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(outliers)\n",
    "Data_normalized <- subset(Wines, select = -c(quality, Color))\n",
    "Data_normalized <- scores(Data_normalized)\n",
    "Data_normalized$quality <- Wines$quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_s <- Data_normalized[wine_ind, ]\n",
    "test_s <- Data_normalized[-wine_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.train_s <- train_s$quality\n",
    "train_s$quality <- NULL\n",
    "x.train_s <- do.call(cbind, train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_cross <- tune.knn(x.train_s, y.train_s, k = 5:50, tunecontrol = tune.control(sampling = 'cross', cross = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.442732773420406"
      ],
      "text/latex": [
       "0.442732773420406"
      ],
      "text/markdown": [
       "0.442732773420406"
      ],
      "text/plain": [
       "[1] 0.4427328"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "__ignored__": ""
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cross$best.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>k</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>13</th><td>17</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & k\\\\\n",
       "\\hline\n",
       "\t13 & 17\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | k | \n",
       "|---|\n",
       "| 13 | 17 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   k \n",
       "13 17"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "__ignored__": ""
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cross$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "La valeur optimale obtenue pour k est 17.\n",
    "On utilisera cette valeur par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.test_s <- test_s$quality\n",
    "test_s$quality <- NULL\n",
    "x.test_s <- do.call(cbind, test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(class)\n",
    "knn.pred<-knn(x.train_s, x.test_s, y.train_s, k = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        y.test_s\n",
       "knn.pred   3   4   5   6   7   8   9\n",
       "       3   0   0   0   0   0   0   0\n",
       "       4   0   1   1   0   0   0   0\n",
       "       5   3  35 334 156  11   2   0\n",
       "       6   3  19 190 451 161  24   0\n",
       "       7   0   0   9  93 101  24   2\n",
       "       8   0   0   0   1   3   1   0\n",
       "       9   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "__ignored__": ""
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table(knn.pred, y.test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.4535385\n"
     ]
    }
   ],
   "source": [
    "currentError = sum(knn.pred!=y.test_s)/nrow(test)\n",
    "print(currentError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La valeur optimale pour k est 17.\n",
    "\n",
    "Au final, l'érreur de prédiction est assez importante en kNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest\n",
    "On va maintenand essayer un modèle de type foret aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(formula = quality ~ ., data = train, ntree = 500) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 500\n",
      "No. of variables tried at each split: 3\n",
      "\n",
      "        OOB estimate of  error rate: 31.63%\n",
      "Confusion matrix:\n",
      "  3  4    5    6   7  8 9 class.error\n",
      "3 0  0   14    9   0  0 0   1.0000000\n",
      "4 0 22   80   66   1  0 0   0.8698225\n",
      "5 0  3 1132  431  13  0 0   0.2830906\n",
      "6 0  3  316 1687 127  4 0   0.2105756\n",
      "7 0  0   21  355 435  3 0   0.4656020\n",
      "8 0  0    1   46  46 55 0   0.6283784\n",
      "9 0  0    0    1   1  0 0   1.0000000\n"
     ]
    }
   ],
   "source": [
    "fit <- randomForest(quality ~., data = train, ntree=500)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Erreur avec random Forest:\" \"0.312615384615385\"         \n"
     ]
    }
   ],
   "source": [
    "rf.predictions = predict(fit,test)\n",
    "summary(rf.predictions)\n",
    "currentError=sum(rf.predictions!=test[,12])/nrow(test)\n",
    "\n",
    "#print(currentError)\n",
    "print(c('Erreur avec random Forest:',currentError))\n",
    "#Le taux de prediction est meilleur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random forest est le modèle qui donne l'érreur de prédiction la plus faible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rééquilibrage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons constaté que le jeu de donnée est dééquilibré, principalement sous representation des classes 3 et 9. \n",
    "\n",
    "Nous allons utiliser la fonction SMOTE qui combine oversampling de la classe minoritaire et undersampling des autres. Les nouvelles données générées utilisent l'algorithme de plus proches voisins, avec par défaut un k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Initial training:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   3    4    5    6    7    8    9 \n",
       "  23  169 1579 2137  814  148    2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"After first SMOTE:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  3   4   5   6   7   8   9 \n",
       "  6  24 229 380 133  28  22 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(DMwR)\n",
    "\n",
    "print(\"Initial training:\")\n",
    "table(train$quality)\n",
    "#On va essayer de re-equilibrer\n",
    "train_r <- SMOTE(quality ~., train, perc.over= 1000, perc.under = 4000)\n",
    "print(\"After first SMOTE:\")\n",
    "table(train_r$quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ré-equilibré la classe 9 (mais toujours pas la classe 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_re <- SMOTE(quality ~., train_r, perc.over= 500, perc.under = 2000)\n",
    "#newTrain <- SMOTE(quality ~., newTrain,perc.over= 500,k=5, perc.under = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"After second SMOTE:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  3   4   5   6   7   8   9 \n",
       " 36  10 167 287  96  21   9 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"After second SMOTE:\")\n",
    "table(train_re$quality)\n",
    "\n",
    "#barplot(table(Wines$quality))\n",
    "#On a ré-equilibré la classe 9 et la classe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons ainsi un échantillon qui est plus équilibré mais dont les nouvelles données générées sur les classes 3 et 9, sont obtenu grace à l'algorithme des plus proches voisins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent utiliser les algorithmes étudiés précédemment sur ces données rééquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(formula = quality ~ ., data = train_re, ntree = 500) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 500\n",
      "No. of variables tried at each split: 3\n",
      "\n",
      "        OOB estimate of  error rate: 19.65%\n",
      "Confusion matrix:\n",
      "   3 4   5   6  7  8 9 class.error\n",
      "3 36 0   0   0  0  0 0   0.0000000\n",
      "4  0 4   3   3  0  0 0   0.6000000\n",
      "5  1 0 119  47  0  0 0   0.2874251\n",
      "6  0 0  17 258 12  0 0   0.1010453\n",
      "7  0 0   2  28 66  0 0   0.3125000\n",
      "8  0 0   1   3  6 11 0   0.4761905\n",
      "9  0 0   0   0  0  0 9   0.0000000\n"
     ]
    }
   ],
   "source": [
    "fit <- randomForest(quality ~., data = train_re, ntree=500)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les résultats sur l'échantillon d'entrainement permettent de prédire de façon assez precise les classes précédemment sous representées. Et le taux d'erreur est très faible comparativement au résultats précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.predictions <- predict(fit, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Erreur avec random Forest:\" \"0.486769230769231\"         \n"
     ]
    }
   ],
   "source": [
    "currentError=sum(rf.predictions!=test[,12])/nrow(test)\n",
    "\n",
    "#print(currentError)\n",
    "print(c('Erreur avec random Forest:',currentError))\n",
    "#Le taux de prediction est meilleur\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              \n",
       "rf.predictions   3   4   5   6   7   8   9\n",
       "             3   0   0  15   6   0   0   0\n",
       "             4   0   0   2   0   0   0   0\n",
       "             5   0  12 214  92   8   1   0\n",
       "             6   6  34 326 558 196  33   1\n",
       "             7   1   1   2  40  59   8   2\n",
       "             8   0   0   0   3   2   3   0\n",
       "             9   0   0   0   0   0   0   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(rf.predictions, test$quality )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Premiere conclusion:\n",
    "Malgré le ré-equilibrage (avec la méthode smote), les résultats sur l'échantillon de test sont décevant et notamment nettement moins bon que sur la base d'entrainement, ce qui en général est caractéristique d'un cas de surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_cross <- tune(svm, quality ~., data = train_re,\n",
    "                  ranges = list(kernel =c('radial', 'sigmoid'),\n",
    "                                gamma = c(0.5, 1, 2, 4),\n",
    "                                cost = c(0.1, 1, 10, 100, 1000)),\n",
    "                  tunecontrol = tune.control(sampling = 'cross', cross = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.249231746031746"
      ],
      "text/latex": [
       "0.249231746031746"
      ],
      "text/markdown": [
       "0.249231746031746"
      ],
      "text/plain": [
       "[1] 0.2492317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVM_cross$best.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>kernel</th><th scope=col>gamma</th><th scope=col>cost</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>25</th><td>radial</td><td>0.5   </td><td>100   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & kernel & gamma & cost\\\\\n",
       "\\hline\n",
       "\t25 & radial & 0.5    & 100   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | kernel | gamma | cost | \n",
       "|---|\n",
       "| 25 | radial | 0.5    | 100    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   kernel gamma cost\n",
       "25 radial 0.5   100 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVM_cross$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.model <- svm(quality ~ ., data = train_re, kernel='radial', cost = 100, gamma = 0.5)\n",
    "svm.pred <- predict(svm.model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "svm.pred   3   4   5   6   7   8   9\n",
       "       3   0   0   3   0   0   0   0\n",
       "       4   0   2   3   0   0   0   0\n",
       "       5   2  13 188 126  17   0   0\n",
       "       6   5  30 354 497 167  29   0\n",
       "       7   0   2   9  70  74  10   3\n",
       "       8   0   0   2   6   7   6   0\n",
       "       9   0   0   0   0   0   0   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(svm.pred, test$quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.528\n"
     ]
    }
   ],
   "source": [
    "currentError = sum(svm.pred!=test[,'quality'])/nrow(test)\n",
    "print(currentError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premiere conclusion:\n",
    "Comme dans le cas des forêts aléatoires, les résultats relativement bon sur la base d'entrainement se dégradent fortement sur la base de test, laissant supposer un problème de surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à present tester l'algorithme des K plus proches voisins, qui avait obtenu les moins bon résultats sur les données non rééchantillonnées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_normalized <- subset(Wines, select = -c(quality, Color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_normalized <- scores(Data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_normalized$quality <- Wines$quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_ind <- sample(nrow(Wines), 0.75 * nrow(Wines))\n",
    "train_s <- Data_normalized[wine_ind, ]\n",
    "test_s <- Data_normalized[-wine_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.train_s <- train_s$quality\n",
    "train_s$quality <- NULL\n",
    "x.train_s <- do.call(cbind, train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_cross <- tune.knn(x.train_s, y.train_s, k = 5:50, tunecontrol = tune.control(sampling = 'cross', cross = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.451970304849155"
      ],
      "text/latex": [
       "0.451970304849155"
      ],
      "text/markdown": [
       "0.451970304849155"
      ],
      "text/plain": [
       "[1] 0.4519703"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNN_cross$best.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>k</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>22</th><td>26</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & k\\\\\n",
       "\\hline\n",
       "\t22 & 26\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | k | \n",
       "|---|\n",
       "| 22 | 26 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   k \n",
       "22 26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNN_cross$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.test_s <- test_s$quality\n",
    "test_s$quality <- NULL\n",
    "x.test_s <- do.call(cbind, test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(class)\n",
    "knn.pred<-knn(x.train_s, x.test_s, y.train_s, k = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        y.test_s\n",
       "knn.pred   3   4   5   6   7   8   9\n",
       "       3   0   0   0   0   0   0   0\n",
       "       4   0   0   0   0   0   0   0\n",
       "       5   4  39 309 163  14   0   0\n",
       "       6   1  19 198 492 146  21   0\n",
       "       7   0   0  12  78 101  26   0\n",
       "       8   0   0   0   1   1   0   0\n",
       "       9   0   0   0   0   0   0   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(knn.pred, y.test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.4449231\n"
     ]
    }
   ],
   "source": [
    "currentError = sum(knn.pred!=y.test_s)/nrow(x.test_s)\n",
    "print(currentError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premiere conclusion:\n",
    "Contrairement au foret aléatoire et SVM les résultats ne diminuent que très faiblement entre l'apprentissage et le teste mais les résultats restent décevant avec des taux d'erreur de plus de 40%, très proches de ceux obtenus sur données brutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons testé 3 stratégies (KNN, SVM et Random Forest) sur le jeu de données afin de prédire la qualité du vin, en nous plaçant dans un contexte de classification multi-classe. Le jeu de données étant particulièrement déséquilibré, nous avons testé ces stratégies sur le jeu de données \"brutes\" ainsi que sur des données rééquilibrées.\n",
    "\n",
    "Nous avons effectué des validations croisées, nous permettant de calibrer nos modèles et ainsi de déterminer leurs performances.\n",
    "L'algorithme KNN est clairement celui présentant les résultats le plus décevant avec des taux d'erreur au-dessus de 40%. Le k optimal étant assez important il ne permet pas/très mal de capturer les classes sous représentées. \n",
    "\n",
    "Le séparateur à vaste marge permet de capturer les relations non linéaires entre les variables explicatives et la qualité du vin, il présente un taux de bonne réponse de l'ordre de 60%, ce qui n'est pas si mal compte tenu de la difficulté de l'exercice.\n",
    "Enfin, l'algorithme des forêts aléatoires obtient les meilleurs résultats,  notamment sur les classes à faible nombre d’observation (notes 4 et 8). \n",
    "\n",
    "Le meilleur taux de prédiction que nous ayons obtenu est de 31% pour le modèle de forêt aléatoire.\n",
    "\n",
    "Les données étant mal réparties entre les classes, problème classique en apprentissage statistique, nous avons essayé de le rééchantillonner, en utilisant la fonction SMOTE. Nous l’avons appliqué 2 fois de manières successives  ce qui nous a permis d’obtenir un nouvel échantillon d’apprentissage à peu près équilibré. Mais cette fonction qui combine à la fois oversampling et undersampling génère de nouvelles données pour l’oversampling en utilisant l’algorithme des plus proches voisins (avec  k=5, valeur comme défaut). La classe 9 n’ayant que 5 observations les nouvelles données risque d’être légèrement bruitées. Afin d’étudier cet impact nous avons essayé plusieurs valeurs de k, et avons obtenu des résultats relativement similaires (testes non présentés dans le notebook) .\n",
    "\n",
    "\n",
    "Les résultats obtenus par rééchantillonnage sont assez décevant, on observe une forte augmentation du taux d’erreur entre l’apprentissage et le teste, ce qui nous oriente vers de l’overfitting. Afin d’éviter ce phénomène nous aurions pu mettre en place un rééquilibrage en utilisant juste de l’undersampling mais le faible nombre d’observations de certaines classes, auraient conduit à un jeu de donnée relativement restreint.\n",
    "\n",
    "\n",
    "De plus, nous avons choisi d'étudier ce problème sous le prisme de la classification, une étude en régréssion nous aurait certainement permis d'afficher de meilleur résultats.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.4.3 (Juniper)",
   "language": "R",
   "name": "juniper_r3.4.3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".R",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
